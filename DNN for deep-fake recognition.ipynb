{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"DNN for deep-fake recognition.ipynb","provenance":[],"collapsed_sections":["8JO1FZfwZyZ-"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sRhBfsLNARhc"},"source":["# ===== CREAZIONE DATASET FACCE A PARTIRE DAI VIDEO =====#"]},{"cell_type":"code","metadata":{"id":"-GhcuTUjARiG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639953739053,"user_tz":-60,"elapsed":22672,"user":{"displayName":"Emanuele D'Ajello","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05320300414395853237"}},"outputId":"56085920-1252-4a89-b4e5-9bff701fe2da"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"pmwIlWx-ARiL"},"source":["!cp -r /content/drive/MyDrive/ESM/hidden_tech.zip /content\n","!unzip hidden_tech.zip\n","!rm /content/hidden_tech.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A9myn9vpARiN"},"source":["!cp -r /content/drive/MyDrive/ESM/Dataset.zip /content\n","!unzip Dataset.zip\n","!rm /content/Dataset.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"atZclemqARiQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639953765741,"user_tz":-60,"elapsed":7993,"user":{"displayName":"Emanuele D'Ajello","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05320300414395853237"}},"outputId":"8d1b568a-3038-420c-acae-0bf20c89ce6b"},"source":["# Avvio dello script che costruisce il dataset delle Facce a partire dal dataset dei video\n","!python /content/hidden_tech/build_dataset.py"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["LOG: Creando il dataset in ./Faces\n","Traceback (most recent call last):\n","  File \"/content/hidden_tech/build_dataset.py\", line 171, in <module>\n","    extract_faces_from_dataset_subfolder('fake', 10,  15,  -1, last_processed_video_index)\n","  File \"/content/hidden_tech/build_dataset.py\", line 82, in extract_faces_from_dataset_subfolder\n","    video_names = [f for f in os.listdir(path.join(old_dataset_path, old_dataset_sub_dir)) if path.isfile(path.join(old_dataset_path, old_dataset_sub_dir, f))]\n","FileNotFoundError: [Errno 2] No such file or directory: './Dataset/fake'\n"]}]},{"cell_type":"code","metadata":{"id":"b8v0a8JkWjxk","executionInfo":{"status":"ok","timestamp":1639953768402,"user_tz":-60,"elapsed":1289,"user":{"displayName":"Emanuele D'Ajello","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05320300414395853237"}}},"source":["!mkdir Faces_train\n","!mkdir Faces_test\n","!mkdir Faces_validation\n","\n","!mkdir Faces_train/fake\n","!mkdir Faces_train/real\n","!mkdir Faces_test/fake\n","!mkdir Faces_test/real\n","!mkdir Faces_validation/fake\n","!mkdir Faces_validation/real"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y3MUyqHvBxK1","colab":{"base_uri":"https://localhost:8080/","height":246},"executionInfo":{"status":"error","timestamp":1639953771851,"user_tz":-60,"elapsed":1189,"user":{"displayName":"Emanuele D'Ajello","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05320300414395853237"}},"outputId":"ad3a46e8-484a-4c39-a043-37bf9ee2a7c6"},"source":["# Script per la suddivisione delle Faces in train, validation e test\n","import os\n","import shutil\n","\n","TRAIN_PERCENTAGE = 70\n","TEST_PERCENTAGE = 15\n","VALIDATION_PERCENTAGE = 100 - TRAIN_PERCENTAGE - TEST_PERCENTAGE\n","\n","faces_fake = [img for img in os.listdir(\"/content/Faces/fake\") if os.path.isfile(f\"/content/Faces/fake/{img}\")]\n","faces_real = [img for img in os.listdir(\"/content/Faces/real\") if os.path.isfile(f\"/content/Faces/real/{img}\")]\n","faces_real = sorted(faces_real)\n","faces_fake = sorted(faces_fake)\n","\n","train_faces_fake = faces_fake[:int(TRAIN_PERCENTAGE/100*len(faces_fake)/10)*10]\n","train_faces_real = faces_real[:int(TRAIN_PERCENTAGE/100*len(faces_real)/100)*100]\n","\n","test_faces_fake = faces_fake[len(train_faces_fake):len(train_faces_fake) + int(TEST_PERCENTAGE/100*len(faces_fake)/10)*10]\n","test_faces_real = faces_real[len(train_faces_real):len(train_faces_real) + int(TEST_PERCENTAGE/100*len(faces_real)/100)*100]\n","\n","validation_faces_fake = faces_fake[len(train_faces_fake) + len(test_faces_fake):]\n","validation_faces_real = faces_real[len(train_faces_real) + len(test_faces_real):]\n","\n","for i in train_faces_fake:\n","  shutil.move(f\"Faces/fake/{i}\",\"Faces_train/fake\")\n","\n","for i in train_faces_real:\n","  shutil.move(f\"Faces/real/{i}\",\"Faces_train/real\")\n","\n","for i in validation_faces_fake:\n","  shutil.move(f\"Faces/fake/{i}\",\"Faces_validation/fake\")\n","\n","for i in validation_faces_real:\n","  shutil.move(f\"Faces/real/{i}\",\"Faces_validation/real\")\n","\n","for i in test_faces_fake:\n","  shutil.move(f\"Faces/fake/{i}\",\"Faces_test/fake\")\n","\n","for i in test_faces_real:\n","  shutil.move(f\"Faces/real/{i}\",\"Faces_test/real\")"],"execution_count":6,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-9f04f6876506>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfaces_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/Faces/fake\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/content/Faces/fake/{img}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mfaces_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/Faces/real\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/content/Faces/real/{img}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mfaces_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfaces_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Faces/real'"]}]},{"cell_type":"markdown","metadata":{"id":"cSuJTnliDabz"},"source":["# ===== IMPORTAZIONE DEL DATASET DI FACCE GIA' SPLITTATE ===== #"]},{"cell_type":"code","metadata":{"id":"e-AvXVLOWRi6"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Qdbaczb9ZU9"},"source":["!cp /content/drive/MyDrive/ESM/Faces_splitted.tar.gz /content\n","!tar -xvzf Faces_splitted.tar.gz\n","!rm /content/Faces_splitted.tar.gz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qq-bh31CM0AL"},"source":["!cp -r /content/drive/MyDrive/ESM/hidden_tech.zip /content\n","!unzip hidden_tech.zip\n","!rm /content/hidden_tech.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fXDKOEFGiaud"},"source":["# ===== CREAZIONE ED ALLENAMENTO DNN ===== #\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"vJKZ6EfOiYLr"},"source":["from hidden_tech import graph_utils as graph\n","from tensorflow import keras\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","import tensorflow.keras.layers as layers\n","import os\n","import sys\n","import json\n","from datetime import datetime\n","\n","model = 0\n","\n","prefix = datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n","\n","batch_size    = 64 #questo Ã¨ il limite !\n","epochs        = 1\n","learning_rate = 0.0001\n","locked_layers = 15\n","\n","log_interval = 100\n","log_file     = prefix + \"_Training.json\"\n","\n","assert os.path.isfile(log_file) == False\n","\n","\n","list_fake = os.listdir(\"Faces_train/fake\") \n","list_real = os.listdir(\"Faces_train/real\")\n","train_total = len(list_fake) + len(list_real)\n","\n","list_fake = os.listdir(\"Faces_validation/fake\") \n","list_real = os.listdir(\"Faces_validation/real\")\n","validation_total = len(list_fake) + len(list_real)\n","\n","img_width = img_height = 224\n","\n","train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.2, horizontal_flip=True)\n","val_datagen   = ImageDataGenerator(rescale=1./255)\n","test_datagen  = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    \"Faces_train\", \n","    target_size = (img_width, img_height), \n","    batch_size = batch_size, \n","    class_mode = 'categorical')\n","\n","val_generator = val_datagen.flow_from_directory(\n","    \"Faces_validation\",\n","    target_size = (img_width,img_height), \n","    batch_size = batch_size, \n","    class_mode = 'categorical')\n","\n","test_generator = test_datagen.flow_from_directory(\n","    \"Faces_test\", \n","    target_size = (img_width,img_height), \n","    batch_size = batch_size, \n","    class_mode = 'categorical', \n","    shuffle = False)\n","\n","# CARICAMENTO CONDIZIONALE DEL MODELLO\n","\n","print(\"Inserisci il path completo del modello che vuoi caricare, altrimenti premi invio crearne uno nuovo\")\n","model_path = input()\n","\n","if( model_path ):\n","  model = keras.models.load_model(model_path)\n","\n","  print(\"Vuoi continuare ad allenare il modello appena caricato? (y/n)\")\n","  choise = input()\n","\n","  if(choise == 'y' or choise == 'Y'):\n","\n","    model.fit(\n","        train_generator,\n","        batch_size=batch_size,\n","        epochs=epochs,\n","        verbose=1,\n","        callbacks=[\n","            graph.SaveCallback(log_file, log_interval, epochs, batch_size, learning_rate, log_interval),\n","            tf.keras.callbacks.ModelCheckpoint(\n","              filepath= prefix + \"_model\",\n","              monitor='val_loss',\n","              mode='min',\n","              save_best_only = True\n","              )\n","            ],\n","        validation_split=0.0,\n","        validation_data=val_generator,\n","        shuffle=False,\n","        class_weight=None,\n","        sample_weight=None,\n","        steps_per_epoch= train_total // batch_size,\n","        validation_steps= validation_total // batch_size,\n","        validation_batch_size=batch_size,\n","        validation_freq=1,\n","        max_queue_size=10,\n","        workers=1,\n","        use_multiprocessing=False,\n","    )\n","\n","else:\n","  print(\"Crea da zero il modello\")\n","  base_model = ResNet50(\n","      weights = 'imagenet', \n","      include_top = False, \n","      input_shape = (img_width, img_height, 3))\n","\n","  #blocco i livelli piÃ¹ in basso\n","  for layer in base_model.layers[:locked_layers]:\n","    layer.trainable = False\n","\n","  #aggiungo i livelli\n","  model = keras.models.Sequential()\n","  model.add(base_model)\n","  model.add(layers.GlobalAveragePooling2D())\n","  \n","  # discussione sull'aggiunta di un altro strato denso\n","  model.add(layers.Dense(3000))\n","  model.add(layers.LeakyReLU(alpha=0.05))\n","  model.add(layers.Dense(2,activation=\"softmax\"))\n","  \n","  model.compile(\n","      loss = keras.losses.categorical_crossentropy,\n","      optimizer = tf.keras.optimizers.Adam(\n","          learning_rate = learning_rate\n","          ),\n","      metrics= [\"accuracy\"]\n","      )\n","\n","  model.fit(\n","          train_generator,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          callbacks=[\n","              graph.SaveCallback(log_file, log_interval,epochs, batch_size, learning_rate, log_interval),\n","              tf.keras.callbacks.ModelCheckpoint(\n","                filepath= prefix + \"_model\",\n","                monitor='val_loss',\n","                mode='min',\n","                save_best_only = True+\n","                )\n","              ],\n","          validation_split=0.0,\n","          validation_data=val_generator,\n","          shuffle=False,\n","          class_weight=None,\n","          sample_weight=None,\n","          steps_per_epoch= train_total // batch_size,\n","          validation_steps= validation_total // batch_size,\n","          validation_batch_size=batch_size,\n","          validation_freq=1,\n","          max_queue_size=10,\n","          workers=1,\n","          use_multiprocessing=False,\n","      )\n","\n","\n","#graph.graph_from_training_data(log_file, True, prefix + '_')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AmcsSIzuxd4k"},"source":["model.evaluate(test_generator, batch_size = batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8JO1FZfwZyZ-"},"source":["# ===== ATTACCO FGSM ===== #\n"]},{"cell_type":"code","metadata":{"id":"m4SqjLeoZyaB"},"source":["!pip install foolbox"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u9B0JrjLZyaC"},"source":["from foolbox.models import TensorFlowModel\n","from foolbox.attacks import FGSM\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IMu4FO6ZZyaC"},"source":["x_true, y_true = next(train_generator)\n","\n","y_pred = model.predict(x_true)\n","y_pred = np.argmax(y_pred, -1) # One hot -> Sparse representation (categorical)\n","y_true = np.argmax(y_true, -1)\n","\n","accuracy = np.mean(y_true == y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9cKC3YLHZyaC"},"source":["from tensorflow import convert_to_tensor\n","\n","attack = FGSM()\n","\n","model_foolbox = TensorFlowModel(model, bounds=(0,1))\n","\n","preclip, x_advs, res = attack(\n","    model_foolbox, \n","    convert_to_tensor(x_true), \n","    convert_to_tensor(y_true), \n","    epsilons=0.01\n","    )\n","\n","x_advs = x_advs.numpy()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hQkHoiOEZyaD"},"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(1)\n","plt.title(\"Prima immagine del batch prima dell'attacco\")\n","plt.imshow(x_true[0])\n","\n","plt.figure(2)\n","plt.title(\"Prima immagine del batch dopo l'attacco\")\n","plt.imshow(x_advs[0])\n","\n","plt.figure(3)\n","plt.title(\"Immagina della perturbazione (intensificata)\")\n","plt.imshow((x_advs[0] - x_true[0])  *100)\n","#mse = np.mean((x_true[0] - x_advs[0])**2)\n","#print('mse =', mse)\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hyaNM2MAZyaD"},"source":["y_pred_advs = model.predict(x_advs)\n","\n","y_pred_advs = np.argmax(y_pred_advs, -1)\n","\n","accuracy_2 = np.mean(y_true == y_pred_advs) # Accuratezza dopo aver moddato il set di input\n","mse = np.mean((x_true - x_advs)**2)    # Quanto abbiamo moddato il set?\n","# psnr = 10* np.log10((x.max**2)/mse)\n","\n","print(f'Accuratezza sul batch prima dell\\'attacco: {accuracy}\\nAccuratezza sul batch dopo l\\'attacco: {accuracy_2}')\n","print(f'MSE tra le immagini del batch prima e dopo l\\'attacco: {mse}')"],"execution_count":null,"outputs":[]}]}